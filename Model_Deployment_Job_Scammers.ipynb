{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81434f9f-e30f-4038-a4e3-cee07eae1f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shubh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shubh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shubh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2025-06-15 17:02:47.849 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\shubh\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-06-15 17:02:47.851 Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import shap\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Custom CSS for modern UI\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    .main {\n",
    "        background-color: #f0f2f6;\n",
    "        padding: 20px;\n",
    "        border-radius: 10px;\n",
    "    }\n",
    "    .stButton>button {\n",
    "        background-color: #4CAF50;\n",
    "        color: white;\n",
    "        border-radius: 5px;\n",
    "        padding: 10px 20px;\n",
    "    }\n",
    "    .stButton>button:hover {\n",
    "        background-color: #45a049;\n",
    "    }\n",
    "    .sidebar .sidebar-content {\n",
    "        background-color: #2c3e50;\n",
    "        color: white;\n",
    "    }\n",
    "    .stSelectbox, .stTextInput, .stTextArea, .stFileUploader {\n",
    "        background-color: white;\n",
    "        border-radius: 5px;\n",
    "        padding: 10px;\n",
    "    }\n",
    "    .stSpinner {\n",
    "        color: #4CAF50;\n",
    "    }\n",
    "    h1, h2, h3 {\n",
    "        color: #2c3e50;\n",
    "    }\n",
    "    .dashboard-container {\n",
    "        background-color: white;\n",
    "        padding: 20px;\n",
    "        border-radius: 10px;\n",
    "        box-shadow: 0 4px 8px rgba(0,0,0,0.1);\n",
    "        margin-bottom: 20px;\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Initialize session state for persisting df and X\n",
    "if 'df' not in st.session_state:\n",
    "    st.session_state.df = None\n",
    "if 'X' not in st.session_state:\n",
    "    st.session_state.X = None\n",
    "\n",
    "# Load the model and preprocessors\n",
    "try:\n",
    "    xgb_model = joblib.load('job_fraud_xgb_revised_threshold_0_2.pkl')\n",
    "    tfidf_desc = joblib.load('tfidf_desc_revised.pkl')\n",
    "    tfidf_comp = joblib.load('tfidf_comp_revised.pkl')\n",
    "    tfidf_title = joblib.load('tfidf_title_revised.pkl')\n",
    "    fraud_rate = joblib.load('fraud_rate.pkl')\n",
    "    st.success(\"Model and preprocessors loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    st.error(f\"Error: {e}. Please ensure all .pkl files are in the same directory as this script.\")\n",
    "    st.stop()\n",
    "\n",
    "# Initialize SHAP explainer\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "\n",
    "# Initialize NLTK tools\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Utility functions for preprocessing\n",
    "def advanced_preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def parse_salary(salary):\n",
    "    if pd.isna(salary) or not isinstance(salary, str):\n",
    "        return 0\n",
    "    try:\n",
    "        salary = salary.replace('$', '').replace(',', '')\n",
    "        low, high = salary.split('-')\n",
    "        return (float(low) + float(high)) / 2\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Prediction function (moved from api.py)\n",
    "def scan_job(job_data):\n",
    "    # Convert the incoming job data to a DataFrame\n",
    "    df = pd.DataFrame([job_data])\n",
    "\n",
    "    # Preprocess the text fields\n",
    "    df['description_clean'] = df['description'].apply(advanced_preprocess_text)\n",
    "    df['company_profile_clean'] = df['company_profile'].apply(advanced_preprocess_text)\n",
    "    df['title_clean'] = df['title'].apply(advanced_preprocess_text)\n",
    "\n",
    "    # Transform text using TF-IDF vectorizers\n",
    "    X_desc = tfidf_desc.transform(df['description_clean'])\n",
    "    X_comp = tfidf_comp.transform(df['company_profile_clean'])\n",
    "    X_title = tfidf_title.transform(df['title_clean'])\n",
    "\n",
    "    # Process salary and binary features\n",
    "    df['has_salary_range'] = 1 if job_data['salary_range'] else 0\n",
    "    df['salary_avg'] = parse_salary(job_data['salary_range'])\n",
    "\n",
    "    # Target encoding for categorical features\n",
    "    cat_features = ['employment_type', 'required_experience', 'industry']\n",
    "    for col in cat_features:\n",
    "        df[f'{col}_target_enc'] = df[col].map(fraud_rate.get(col, {})).fillna(0.048715)\n",
    "\n",
    "    # Additional features\n",
    "    df['desc_length'] = df['description'].apply(len)\n",
    "    df['urgent_flag'] = df['description'].str.contains('urgent|immediate|asap|now|pressing|hurry|limited time', case=False, na=False).astype(int)\n",
    "\n",
    "    # Prepare the feature matrix\n",
    "    binary_features = ['telecommuting', 'has_company_logo', 'has_questions', 'has_salary_range']\n",
    "    X_binary = df[binary_features].values\n",
    "    X_extra = df[['salary_avg', 'desc_length', 'urgent_flag', 'employment_type_target_enc', 'required_experience_target_enc', 'industry_target_enc']].values\n",
    "    X = np.hstack((X_desc.toarray(), X_comp.toarray(), X_title.toarray(), X_binary, X_extra))\n",
    "\n",
    "    # Make prediction\n",
    "    fraud_prob = xgb_model.predict_proba(X)[:, 1][0]\n",
    "    prediction = 1 if fraud_prob >= 0.2 else 0\n",
    "    prediction_label = \"Fraudulent\" if prediction == 1 else \"Genuine\"\n",
    "\n",
    "    return {\n",
    "        \"prediction\": prediction,\n",
    "        \"prediction_label\": prediction_label,\n",
    "        \"fraud_probability\": float(fraud_prob)\n",
    "    }\n",
    "\n",
    "# Streamlit App Setup with Sidebar Navigation\n",
    "st.title(\"Job Scam Detector\")\n",
    "st.sidebar.title(\"Navigation\")\n",
    "st.sidebar.markdown(\"### Explore Features\")\n",
    "page = st.sidebar.selectbox(\"Choose a feature:\", [\"CSV Prediction\", \"API Job Scanner\", \"Retrain Model\", \"Explain Predictions\", \"Email Alerts\"])\n",
    "\n",
    "# Page 1: CSV Prediction with Dashboard\n",
    "if page == \"CSV Prediction\":\n",
    "    st.markdown(\"## Upload a CSV file to detect potential job scams\")\n",
    "    uploaded_file = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        required_columns = ['title', 'description']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            st.error(f\"Missing required columns: {missing_columns}. Please ensure the CSV contains 'title' and 'description'.\")\n",
    "            st.stop()\n",
    "\n",
    "        st.success(\"CSV file uploaded successfully!\")\n",
    "        st.markdown(\"### Data Preview\")\n",
    "        st.dataframe(df.head())\n",
    "\n",
    "        # Clean the Job Data\n",
    "        df = df.drop_duplicates()\n",
    "        if 'job_id' in df.columns:\n",
    "            df = df.drop(columns=['job_id'])\n",
    "\n",
    "        text_columns = ['title', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "        categorical_columns = ['location', 'department', 'employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
    "        for col in text_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].fillna(\"Not Provided\")\n",
    "            else:\n",
    "                df[col] = \"Not Provided\"\n",
    "        for col in categorical_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].fillna(\"Unknown\")\n",
    "            else:\n",
    "                df[col] = \"Unknown\"\n",
    "\n",
    "        binary_columns = ['telecommuting', 'has_company_logo', 'has_questions']\n",
    "        for col in binary_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].fillna(0)\n",
    "            else:\n",
    "                df[col] = 0\n",
    "\n",
    "        df['description_clean'] = df['description'].apply(advanced_preprocess_text)\n",
    "        df['company_profile_clean'] = df['company_profile'].apply(advanced_preprocess_text)\n",
    "        df['title_clean'] = df['title'].apply(advanced_preprocess_text)\n",
    "\n",
    "        X_desc = tfidf_desc.transform(df['description_clean'])\n",
    "        X_comp = tfidf_comp.transform(df['company_profile_clean'])\n",
    "        X_title = tfidf_title.transform(df['title_clean'])\n",
    "\n",
    "        if 'salary_range' in df.columns:\n",
    "            df['has_salary_range'] = df['salary_range'].notnull().astype(int)\n",
    "            df['salary_avg'] = df['salary_range'].apply(parse_salary)\n",
    "        else:\n",
    "            df['has_salary_range'] = 0\n",
    "            df['salary_avg'] = 0\n",
    "\n",
    "        cat_features = ['employment_type', 'required_experience', 'industry']\n",
    "        for col in cat_features:\n",
    "            df[f'{col}_target_enc'] = df[col].map(fraud_rate.get(col, {})).fillna(0.048715)\n",
    "\n",
    "        df['desc_length'] = df['description'].apply(len)\n",
    "        df['urgent_flag'] = df['description'].str.contains('urgent|immediate|asap|now|pressing|hurry|limited time', case=False, na=False).astype(int)\n",
    "\n",
    "        binary_features = ['telecommuting', 'has_company_logo', 'has_questions', 'has_salary_range']\n",
    "        X_binary = df[binary_features].values\n",
    "        X_extra = df[['salary_avg', 'desc_length', 'urgent_flag', 'employment_type_target_enc', 'required_experience_target_enc', 'industry_target_enc']].values\n",
    "        X = np.hstack((X_desc.toarray(), X_comp.toarray(), X_title.toarray(), X_binary, X_extra))\n",
    "\n",
    "        if len(df) == 0:\n",
    "            st.error(\"No valid data to process after preprocessing. Please check your CSV file.\")\n",
    "            st.stop()\n",
    "\n",
    "        with st.spinner('Making predictions...'):\n",
    "            fraud_prob = xgb_model.predict_proba(X)[:, 1]\n",
    "            predictions = (fraud_prob >= 0.2).astype(int)\n",
    "            df['Prediction'] = predictions\n",
    "            df['Fraud_Probability'] = fraud_prob\n",
    "            df['Prediction_Label'] = df['Prediction'].map({0: 'Genuine', 1: 'Fraudulent'})\n",
    "\n",
    "        # Store df and X in session state\n",
    "        st.session_state.df = df\n",
    "        st.session_state.X = X\n",
    "\n",
    "        st.markdown(\"## Prediction Dashboard\", unsafe_allow_html=True)\n",
    "        st.markdown('<div class=\"dashboard-container\">', unsafe_allow_html=True)\n",
    "\n",
    "        # Dashboard Layout\n",
    "        col1, col2 = st.columns(2)\n",
    "\n",
    "        with col1:\n",
    "            st.markdown(\"### Fraud Probability Distribution\")\n",
    "            fig = px.histogram(df, x='Fraud_Probability', nbins=20, title='Fraud Probability Distribution',\n",
    "                               color_discrete_sequence=['#4CAF50'])\n",
    "            fig.update_layout(bargap=0.1, xaxis_title=\"Fraud Probability\", yaxis_title=\"Number of Jobs\")\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        with col2:\n",
    "            st.markdown(\"### Genuine vs. Fraudulent Jobs\")\n",
    "            fraud_counts = df['Prediction_Label'].value_counts()\n",
    "            fig = go.Figure(data=[go.Pie(labels=fraud_counts.index, values=fraud_counts.values,\n",
    "                                         textinfo='label+percent', marker=dict(colors=['#4CAF50', '#FF5733']))])\n",
    "            fig.update_layout(title=\"Genuine vs. Fraudulent Jobs\")\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"### Job Listings with Fraud Predictions\")\n",
    "        result_df = df[['title', 'description', 'Prediction_Label', 'Fraud_Probability']]\n",
    "        st.dataframe(result_df, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"### Top-10 Jobs with Highest Fraud Risk\")\n",
    "        top_10_shady = df.nlargest(10, 'Fraud_Probability')[['title', 'description', 'Prediction_Label', 'Fraud_Probability']]\n",
    "        st.dataframe(top_10_shady, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"### Download Predictions\")\n",
    "        csv = df[['title', 'description', 'Prediction_Label', 'Fraud_Probability']].to_csv(index=False)\n",
    "        b64 = base64.b64encode(csv.encode()).decode()\n",
    "        href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"job_fraud_predictions.csv\">Download CSV File</a>'\n",
    "        st.markdown(href, unsafe_allow_html=True)\n",
    "\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "# Page 2: API Job Scanner (Modified to use local function)\n",
    "elif page == \"API Job Scanner\":\n",
    "    st.subheader(\"Real-Time Job Scanner\")\n",
    "    st.write(\"Enter a single job listing to scan for fraud.\")\n",
    "\n",
    "    with st.form(\"job_scan_form\"):\n",
    "        title = st.text_input(\"Job Title:\", value=\"Software Engineer\")\n",
    "        description = st.text_area(\"Job Description:\", value=\"Urgent hiring for software engineer! Apply now.\")\n",
    "        company_profile = st.text_area(\"Company Profile:\", value=\"Tech Corp\")\n",
    "        employment_type = st.selectbox(\"Employment Type:\", [\"Full-time\", \"Part-time\", \"Contract\", \"Temporary\", \"Unknown\"], index=0)\n",
    "        required_experience = st.selectbox(\"Required Experience:\", [\"Entry level\", \"Mid-Senior level\", \"Associate\", \"Executive\", \"Unknown\"], index=1)\n",
    "        industry = st.selectbox(\"Industry:\", [\"Technology\", \"Finance\", \"Healthcare\", \"Education\", \"Unknown\"], index=0)\n",
    "        salary_range = st.text_input(\"Salary Range (e.g., 50000-70000):\", value=\"\")\n",
    "        telecommuting = st.checkbox(\"Telecommuting\", value=False)\n",
    "        has_company_logo = st.checkbox(\"Has Company Logo\", value=True)\n",
    "        has_questions = st.checkbox(\"Has Questions\", value=False)\n",
    "        submit_button = st.form_submit_button(\"Scan Job\")\n",
    "\n",
    "    if submit_button:\n",
    "        job_data = {\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "            \"company_profile\": company_profile,\n",
    "            \"employment_type\": employment_type,\n",
    "            \"required_experience\": required_experience,\n",
    "            \"industry\": industry,\n",
    "            \"salary_range\": salary_range,\n",
    "            \"telecommuting\": int(telecommuting),\n",
    "            \"has_company_logo\": int(has_company_logo),\n",
    "            \"has_questions\": int(has_questions)\n",
    "        }\n",
    "\n",
    "        with st.spinner(\"Scanning job...\"):\n",
    "            result = scan_job(job_data)\n",
    "            st.success(\"Job scanned successfully!\")\n",
    "            st.write(f\"*Prediction*: {result['prediction_label']}\")\n",
    "            st.write(f\"*Fraud Probability*: {result['fraud_probability']:.2f}\")\n",
    "\n",
    "# Page 3: Retrain Model\n",
    "elif page == \"Retrain Model\":\n",
    "    st.subheader(\"Retrain the Model\")\n",
    "    st.write(\"Upload a labeled CSV file to retrain the model. The CSV must include a 'fraudulent' column with labels (0 or 1).\")\n",
    "\n",
    "    retrain_file = st.file_uploader(\"Choose a labeled CSV file\", type=\"csv\", key=\"retrain_file\")\n",
    "\n",
    "    if retrain_file is not None:\n",
    "        new_data = pd.read_csv(retrain_file)\n",
    "        required_columns = ['title', 'description', 'fraudulent']\n",
    "        missing_columns = [col for col in required_columns if col not in new_data.columns]\n",
    "        if missing_columns:\n",
    "            st.error(f\"Missing required columns: {missing_columns}. Please ensure the CSV contains 'title', 'description', and 'fraudulent'.\")\n",
    "            st.stop()\n",
    "\n",
    "        st.success(\"Labeled data uploaded successfully!\")\n",
    "        st.markdown(\"### Data Preview\")\n",
    "        st.dataframe(new_data.head())\n",
    "\n",
    "        if st.button(\"Retrain Model\"):\n",
    "            with st.spinner(\"Retraining the model...\"):\n",
    "                # Preprocessing\n",
    "                new_data = new_data.drop_duplicates()\n",
    "                if 'job_id' in new_data.columns:\n",
    "                    new_data = new_data.drop(columns=['job_id'])\n",
    "\n",
    "                text_columns = ['title', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "                categorical_columns = ['location', 'department', 'employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
    "                for col in text_columns:\n",
    "                    if col in new_data.columns:\n",
    "                        new_data[col] = new_data[col].fillna(\"Not Provided\")\n",
    "                    else:\n",
    "                        new_data[col] = \"Not Provided\"\n",
    "                for col in categorical_columns:\n",
    "                    if col in new_data.columns:\n",
    "                        new_data[col] = new_data[col].fillna(\"Unknown\")\n",
    "                    else:\n",
    "                        new_data[col] = \"Unknown\"\n",
    "\n",
    "                binary_columns = ['telecommuting', 'has_company_logo', 'has_questions']\n",
    "                for col in binary_columns:\n",
    "                    if col in new_data.columns:\n",
    "                        new_data[col] = new_data[col].fillna(0)\n",
    "                    else:\n",
    "                        new_data[col] = 0\n",
    "\n",
    "                new_data['description_clean'] = new_data['description'].apply(advanced_preprocess_text)\n",
    "                new_data['company_profile_clean'] = new_data['company_profile'].apply(advanced_preprocess_text)\n",
    "                new_data['title_clean'] = new_data['title'].apply(advanced_preprocess_text)\n",
    "\n",
    "                # Retrain TF-IDF vectorizers\n",
    "                tfidf_desc = TfidfVectorizer(max_features=5000)\n",
    "                tfidf_comp = TfidfVectorizer(max_features=5000)\n",
    "                tfidf_title = TfidfVectorizer(max_features=5000)\n",
    "                X_desc = tfidf_desc.fit_transform(new_data['description_clean'])\n",
    "                X_comp = tfidf_comp.fit_transform(new_data['company_profile_clean'])\n",
    "                X_title = tfidf_title.fit_transform(new_data['title_clean'])\n",
    "\n",
    "                if 'salary_range' in new_data.columns:\n",
    "                    new_data['has_salary_range'] = new_data['salary_range'].notnull().astype(int)\n",
    "                    new_data['salary_avg'] = new_data['salary_range'].apply(parse_salary)\n",
    "                else:\n",
    "                    new_data['has_salary_range'] = 0\n",
    "                    new_data['salary_avg'] = 0\n",
    "\n",
    "                # Recalculate fraud rates for target encoding\n",
    "                fraud_rate = {}\n",
    "                cat_features = ['employment_type', 'required_experience', 'industry']\n",
    "                for col in cat_features:\n",
    "                    fraud_rate[col] = new_data.groupby(col)['fraudulent'].mean().to_dict()\n",
    "                for col in cat_features:\n",
    "                    new_data[f'{col}_target_enc'] = new_data[col].map(fraud_rate[col]).fillna(new_data['fraudulent'].mean())\n",
    "\n",
    "                new_data['desc_length'] = new_data['description'].apply(len)\n",
    "                new_data['urgent_flag'] = new_data['description'].str.contains('urgent|immediate|asap|now|pressing|hurry|limited time', case=False, na=False).astype(int)\n",
    "\n",
    "                binary_features = ['telecommuting', 'has_company_logo', 'has_questions', 'has_salary_range']\n",
    "                X_binary = new_data[binary_features].values\n",
    "                X_extra = new_data[['salary_avg', 'desc_length', 'urgent_flag', 'employment_type_target_enc', 'required_experience_target_enc', 'industry_target_enc']].values\n",
    "                X = np.hstack((X_desc.toarray(), X_comp.toarray(), X_title.toarray(), X_binary, X_extra))\n",
    "                y = new_data['fraudulent'].values\n",
    "\n",
    "                # Retrain the XGBoost model\n",
    "                xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "                xgb_model.fit(X, y)\n",
    "\n",
    "                # Save the updated models and vectorizers\n",
    "                joblib.dump(xgb_model, 'job_fraud_xgb_revised_threshold_0_2.pkl')\n",
    "                joblib.dump(tfidf_desc, 'tfidf_desc_revised.pkl')\n",
    "                joblib.dump(tfidf_comp, 'tfidf_comp_revised.pkl')\n",
    "                joblib.dump(tfidf_title, 'tfidf_title_revised.pkl')\n",
    "                joblib.dump(fraud_rate, 'fraud_rate.pkl')\n",
    "\n",
    "                st.success(\"Model retrained and saved successfully! Please restart the app to use the updated model.\")\n",
    "\n",
    "# Page 4: Explain Predictions with SHAP\n",
    "elif page == \"Explain Predictions\":\n",
    "    st.subheader(\"Explain Predictions with SHAP\")\n",
    "    st.write(\"Select a job to see why it was classified as fraudulent or genuine.\")\n",
    "\n",
    "    # Check session state for df and X\n",
    "    if st.session_state.df is None or st.session_state.X is None:\n",
    "        st.error(\"Please run a CSV prediction first on the 'CSV Prediction' page.\")\n",
    "    else:\n",
    "        df = st.session_state.df\n",
    "        X = st.session_state.X\n",
    "        job_titles = df['title'].tolist()\n",
    "        selected_job = st.selectbox(\"Select a job to explain:\", job_titles)\n",
    "        selected_idx = df[df['title'] == selected_job].index[0]\n",
    "\n",
    "        shap_values = explainer.shap_values(X[selected_idx:selected_idx+1])\n",
    "        shap_expected_value = explainer.expected_value\n",
    "\n",
    "        st.markdown(\"### SHAP Force Plot\")\n",
    "        plt.figure()\n",
    "        shap.force_plot(shap_expected_value, shap_values, X[selected_idx:selected_idx+1], matplotlib=True, show=False)\n",
    "        st.pyplot(plt)\n",
    "\n",
    "        # Define binary_features\n",
    "        binary_features = ['telecommuting', 'has_company_logo', 'has_questions', 'has_salary_range']\n",
    "        \n",
    "        feature_names = (tfidf_desc.get_feature_names_out().tolist() +\n",
    "                         tfidf_comp.get_feature_names_out().tolist() +\n",
    "                         tfidf_title.get_feature_names_out().tolist() +\n",
    "                         binary_features +\n",
    "                         ['salary_avg', 'desc_length', 'urgent_flag', 'employment_type_target_enc',\n",
    "                          'required_experience_target_enc', 'industry_target_enc'])\n",
    "        st.write(\"Note: Features are in order: description, company profile, title, binary features, and extra features.\")\n",
    "\n",
    "# Page 5: Email Alerts for High-Risk Jobs\n",
    "elif page == \"Email Alerts\":\n",
    "    st.subheader(\"Email Alerts for High-Risk Jobs\")\n",
    "    st.write(\"Enter your email credentials to send alerts for jobs with fraud probability > 80%.\")\n",
    "\n",
    "    # Check session state for df\n",
    "    if st.session_state.df is None:\n",
    "        st.error(\"Please run a CSV prediction first on the 'CSV Prediction' page.\")\n",
    "    else:\n",
    "        df = st.session_state.df\n",
    "        recipient_email = st.text_input(\"Recipient Email Address:\")\n",
    "        sender_email = st.text_input(\"Sender Email Address (e.g., your Gmail):\")\n",
    "        sender_password = st.text_input(\"Sender Email Password (e.g., Gmail App Password):\", type=\"password\")\n",
    "\n",
    "        if st.button(\"Send Email Alert\"):\n",
    "            if not recipient_email or not sender_email or not sender_password:\n",
    "                st.error(\"Please fill in all email fields.\")\n",
    "            else:\n",
    "                high_risk_jobs = df[df['Fraud_Probability'] > 0.8][['title', 'description', 'Fraud_Probability']]\n",
    "\n",
    "                if len(high_risk_jobs) == 0:\n",
    "                    st.warning(\"No high-risk jobs (fraud probability > 80%) found.\")\n",
    "                else:\n",
    "                    subject = \"High-Risk Job Listings Alert\"\n",
    "                    body = \"The following jobs have a fraud probability greater than 80%:\\n\\n\"\n",
    "                    for idx, row in high_risk_jobs.iterrows():\n",
    "                        body += f\"Title: {row['title']}\\nDescription: {row['description']}\\nFraud Probability: {row['Fraud_Probability']:.2f}\\n\\n\"\n",
    "\n",
    "                    msg = MIMEMultipart()\n",
    "                    msg['From'] = sender_email\n",
    "                    msg['To'] = recipient_email\n",
    "                    msg['Subject'] = subject\n",
    "                    msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "                    try:\n",
    "                        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "                        server.starttls()\n",
    "                        server.login(sender_email, sender_password)\n",
    "                        server.sendmail(sender_email, recipient_email, msg.as_string())\n",
    "                        server.quit()\n",
    "                        st.success(f\"Email alert sent to {recipient_email} with {len(high_risk_jobs)} high-risk jobs!\")\n",
    "                    except Exception as e:\n",
    "                        st.error(f\"Failed to send email: {e}. Ensure your credentials are correct and you’re using an app-specific password for Gmail.\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"*App developed by Interpretive Edge*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8901b5ff-dff9-4e69-965c-de957a56335a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app_new.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app_new.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import shap\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Custom CSS for modern UI\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    .main {\n",
    "        background-color: #f0f2f6;\n",
    "        padding: 20px;\n",
    "        border-radius: 10px;\n",
    "    }\n",
    "    .stButton>button {\n",
    "        background-color: #4CAF50;\n",
    "        color: white;\n",
    "        border-radius: 5px;\n",
    "        padding: 10px 20px;\n",
    "    }\n",
    "    .stButton>button:hover {\n",
    "        background-color: #45a049;\n",
    "    }\n",
    "    .sidebar .sidebar-content {\n",
    "        background-color: #2c3e50;\n",
    "        color: white;\n",
    "    }\n",
    "    .stSelectbox, .stTextInput, .stTextArea, .stFileUploader {\n",
    "        background-color: white;\n",
    "        border-radius: 5px;\n",
    "        padding: 10px;\n",
    "    }\n",
    "    .stSpinner {\n",
    "        color: #4CAF50;\n",
    "    }\n",
    "    h1, h2, h3 {\n",
    "        color: #2c3e50;\n",
    "    }\n",
    "    .dashboard-container {\n",
    "        background-color: white;\n",
    "        padding: 20px;\n",
    "        border-radius: 10px;\n",
    "        box-shadow: 0 4px 8px rgba(0,0,0,0.1);\n",
    "        margin-bottom: 20px;\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Initialize session state for persisting df and X\n",
    "if 'df' not in st.session_state:\n",
    "    st.session_state.df = None\n",
    "if 'X' not in st.session_state:\n",
    "    st.session_state.X = None\n",
    "\n",
    "# Load the model and preprocessors\n",
    "try:\n",
    "    xgb_model = joblib.load('job_fraud_xgb_revised_threshold_0_2.pkl')\n",
    "    tfidf_desc = joblib.load('tfidf_desc_revised.pkl')\n",
    "    tfidf_comp = joblib.load('tfidf_comp_revised.pkl')\n",
    "    tfidf_title = joblib.load('tfidf_title_revised.pkl')\n",
    "    fraud_rate = joblib.load('fraud_rate.pkl')\n",
    "    st.success(\"Model and preprocessors loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    st.error(f\"Error: {e}. Please ensure all .pkl files are in the same directory as this script.\")\n",
    "    st.stop()\n",
    "\n",
    "# Initialize SHAP explainer\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "\n",
    "# Initialize NLTK tools\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Utility functions for preprocessing\n",
    "def advanced_preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def parse_salary(salary):\n",
    "    if pd.isna(salary) or not isinstance(salary, str):\n",
    "        return 0\n",
    "    try:\n",
    "        salary = salary.replace('$', '').replace(',', '')\n",
    "        low, high = salary.split('-')\n",
    "        return (float(low) + float(high)) / 2\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Prediction function (moved from api.py)\n",
    "def scan_job(job_data):\n",
    "    # Convert the incoming job data to a DataFrame\n",
    "    df = pd.DataFrame([job_data])\n",
    "\n",
    "    # Preprocess the text fields\n",
    "    df['description_clean'] = df['description'].apply(advanced_preprocess_text)\n",
    "    df['company_profile_clean'] = df['company_profile'].apply(advanced_preprocess_text)\n",
    "    df['title_clean'] = df['title'].apply(advanced_preprocess_text)\n",
    "\n",
    "    # Transform text using TF-IDF vectorizers\n",
    "    X_desc = tfidf_desc.transform(df['description_clean'])\n",
    "    X_comp = tfidf_comp.transform(df['company_profile_clean'])\n",
    "    X_title = tfidf_title.transform(df['title_clean'])\n",
    "\n",
    "    # Process salary and binary features\n",
    "    df['has_salary_range'] = 1 if job_data['salary_range'] else 0\n",
    "    df['salary_avg'] = parse_salary(job_data['salary_range'])\n",
    "\n",
    "    # Target encoding for categorical features\n",
    "    cat_features = ['employment_type', 'required_experience', 'industry']\n",
    "    for col in cat_features:\n",
    "        df[f'{col}_target_enc'] = df[col].map(fraud_rate.get(col, {})).fillna(0.048715)\n",
    "\n",
    "    # Additional features\n",
    "    df['desc_length'] = df['description'].apply(len)\n",
    "    df['urgent_flag'] = df['description'].str.contains('urgent|immediate|asap|now|pressing|hurry|limited time', case=False, na=False).astype(int)\n",
    "\n",
    "    # Prepare the feature matrix\n",
    "    binary_features = ['telecommuting', 'has_company_logo', 'has_questions', 'has_salary_range']\n",
    "    X_binary = df[binary_features].values\n",
    "    X_extra = df[['salary_avg', 'desc_length', 'urgent_flag', 'employment_type_target_enc', 'required_experience_target_enc', 'industry_target_enc']].values\n",
    "    X = np.hstack((X_desc.toarray(), X_comp.toarray(), X_title.toarray(), X_binary, X_extra))\n",
    "\n",
    "    # Make prediction\n",
    "    fraud_prob = xgb_model.predict_proba(X)[:, 1][0]\n",
    "    prediction = 1 if fraud_prob >= 0.2 else 0\n",
    "    prediction_label = \"Fraudulent\" if prediction == 1 else \"Genuine\"\n",
    "\n",
    "    return {\n",
    "        \"prediction\": prediction,\n",
    "        \"prediction_label\": prediction_label,\n",
    "        \"fraud_probability\": float(fraud_prob)\n",
    "    }\n",
    "\n",
    "# Streamlit App Setup with Sidebar Navigation\n",
    "st.title(\"Job Scam Detector\")\n",
    "st.sidebar.title(\"Navigation\")\n",
    "st.sidebar.markdown(\"### Explore Features\")\n",
    "page = st.sidebar.selectbox(\"Choose a feature:\", [\"CSV Prediction\", \"API Job Scanner\", \"Retrain Model\", \"Explain Predictions\", \"Email Alerts\"])\n",
    "\n",
    "# Page 1: CSV Prediction with Dashboard\n",
    "if page == \"CSV Prediction\":\n",
    "    st.markdown(\"## Upload a CSV file to detect potential job scams\")\n",
    "    uploaded_file = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        required_columns = ['title', 'description']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            st.error(f\"Missing required columns: {missing_columns}. Please ensure the CSV contains 'title' and 'description'.\")\n",
    "            st.stop()\n",
    "\n",
    "        st.success(\"CSV file uploaded successfully!\")\n",
    "        st.markdown(\"### Data Preview\")\n",
    "        st.dataframe(df.head())\n",
    "\n",
    "        # Clean the Job Data\n",
    "        df = df.drop_duplicates()\n",
    "        if 'job_id' in df.columns:\n",
    "            df = df.drop(columns=['job_id'])\n",
    "\n",
    "        text_columns = ['title', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "        categorical_columns = ['location', 'department', 'employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
    "        for col in text_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].fillna(\"Not Provided\")\n",
    "            else:\n",
    "                df[col] = \"Not Provided\"\n",
    "        for col in categorical_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].fillna(\"Unknown\")\n",
    "            else:\n",
    "                df[col] = \"Unknown\"\n",
    "\n",
    "        binary_columns = ['telecommuting', 'has_company_logo', 'has_questions']\n",
    "        for col in binary_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].fillna(0)\n",
    "            else:\n",
    "                df[col] = 0\n",
    "\n",
    "        df['description_clean'] = df['description'].apply(advanced_preprocess_text)\n",
    "        df['company_profile_clean'] = df['company_profile'].apply(advanced_preprocess_text)\n",
    "        df['title_clean'] = df['title'].apply(advanced_preprocess_text)\n",
    "\n",
    "        X_desc = tfidf_desc.transform(df['description_clean'])\n",
    "        X_comp = tfidf_comp.transform(df['company_profile_clean'])\n",
    "        X_title = tfidf_title.transform(df['title_clean'])\n",
    "\n",
    "        if 'salary_range' in df.columns:\n",
    "            df['has_salary_range'] = df['salary_range'].notnull().astype(int)\n",
    "            df['salary_avg'] = df['salary_range'].apply(parse_salary)\n",
    "        else:\n",
    "            df['has_salary_range'] = 0\n",
    "            df['salary_avg'] = 0\n",
    "\n",
    "        cat_features = ['employment_type', 'required_experience', 'industry']\n",
    "        for col in cat_features:\n",
    "            df[f'{col}_target_enc'] = df[col].map(fraud_rate.get(col, {})).fillna(0.048715)\n",
    "\n",
    "        df['desc_length'] = df['description'].apply(len)\n",
    "        df['urgent_flag'] = df['description'].str.contains('urgent|immediate|asap|now|pressing|hurry|limited time', case=False, na=False).astype(int)\n",
    "\n",
    "        binary_features = ['telecommuting', 'has_company_logo', 'has_questions', 'has_salary_range']\n",
    "        X_binary = df[binary_features].values\n",
    "        X_extra = df[['salary_avg', 'desc_length', 'urgent_flag', 'employment_type_target_enc', 'required_experience_target_enc', 'industry_target_enc']].values\n",
    "        X = np.hstack((X_desc.toarray(), X_comp.toarray(), X_title.toarray(), X_binary, X_extra))\n",
    "\n",
    "        if len(df) == 0:\n",
    "            st.error(\"No valid data to process after preprocessing. Please check your CSV file.\")\n",
    "            st.stop()\n",
    "\n",
    "        with st.spinner('Making predictions...'):\n",
    "            fraud_prob = xgb_model.predict_proba(X)[:, 1]\n",
    "            predictions = (fraud_prob >= 0.2).astype(int)\n",
    "            df['Prediction'] = predictions\n",
    "            df['Fraud_Probability'] = fraud_prob\n",
    "            df['Prediction_Label'] = df['Prediction'].map({0: 'Genuine', 1: 'Fraudulent'})\n",
    "\n",
    "        # Store df and X in session state\n",
    "        st.session_state.df = df\n",
    "        st.session_state.X = X\n",
    "\n",
    "        st.markdown(\"## Prediction Dashboard\", unsafe_allow_html=True)\n",
    "        st.markdown('<div class=\"dashboard-container\">', unsafe_allow_html=True)\n",
    "\n",
    "        # Dashboard Layout\n",
    "        col1, col2 = st.columns(2)\n",
    "\n",
    "        with col1:\n",
    "            st.markdown(\"### Fraud Probability Distribution\")\n",
    "            fig = px.histogram(df, x='Fraud_Probability', nbins=20, title='Fraud Probability Distribution',\n",
    "                               color_discrete_sequence=['#4CAF50'])\n",
    "            fig.update_layout(bargap=0.1, xaxis_title=\"Fraud Probability\", yaxis_title=\"Number of Jobs\")\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        with col2:\n",
    "            st.markdown(\"### Genuine vs. Fraudulent Jobs\")\n",
    "            fraud_counts = df['Prediction_Label'].value_counts()\n",
    "            fig = go.Figure(data=[go.Pie(labels=fraud_counts.index, values=fraud_counts.values,\n",
    "                                         textinfo='label+percent', marker=dict(colors=['#4CAF50', '#FF5733']))])\n",
    "            fig.update_layout(title=\"Genuine vs. Fraudulent Jobs\")\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"### Job Listings with Fraud Predictions\")\n",
    "        result_df = df[['title', 'description', 'Prediction_Label', 'Fraud_Probability']]\n",
    "        st.dataframe(result_df, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"### Top-10 Jobs with Highest Fraud Risk\")\n",
    "        top_10_shady = df.nlargest(10, 'Fraud_Probability')[['title', 'description', 'Prediction_Label', 'Fraud_Probability']]\n",
    "        st.dataframe(top_10_shady, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"### Download Predictions\")\n",
    "        csv = df[['title', 'description', 'Prediction_Label', 'Fraud_Probability']].to_csv(index=False)\n",
    "        b64 = base64.b64encode(csv.encode()).decode()\n",
    "        href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"job_fraud_predictions.csv\">Download CSV File</a>'\n",
    "        st.markdown(href, unsafe_allow_html=True)\n",
    "\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "# Page 2: API Job Scanner (Modified to use local function)\n",
    "elif page == \"API Job Scanner\":\n",
    "    st.subheader(\"Real-Time Job Scanner\")\n",
    "    st.write(\"Enter a single job listing to scan for fraud.\")\n",
    "\n",
    "    with st.form(\"job_scan_form\"):\n",
    "        title = st.text_input(\"Job Title:\", value=\"Software Engineer\")\n",
    "        description = st.text_area(\"Job Description:\", value=\"Urgent hiring for software engineer! Apply now.\")\n",
    "        company_profile = st.text_area(\"Company Profile:\", value=\"Tech Corp\")\n",
    "        employment_type = st.selectbox(\"Employment Type:\", [\"Full-time\", \"Part-time\", \"Contract\", \"Temporary\", \"Unknown\"], index=0)\n",
    "        required_experience = st.selectbox(\"Required Experience:\", [\"Entry level\", \"Mid-Senior level\", \"Associate\", \"Executive\", \"Unknown\"], index=1)\n",
    "        industry = st.selectbox(\"Industry:\", [\"Technology\", \"Finance\", \"Healthcare\", \"Education\", \"Unknown\"], index=0)\n",
    "        salary_range = st.text_input(\"Salary Range (e.g., 50000-70000):\", value=\"\")\n",
    "        telecommuting = st.checkbox(\"Telecommuting\", value=False)\n",
    "        has_company_logo = st.checkbox(\"Has Company Logo\", value=True)\n",
    "        has_questions = st.checkbox(\"Has Questions\", value=False)\n",
    "        submit_button = st.form_submit_button(\"Scan Job\")\n",
    "\n",
    "    if submit_button:\n",
    "        job_data = {\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "            \"company_profile\": company_profile,\n",
    "            \"employment_type\": employment_type,\n",
    "            \"required_experience\": required_experience,\n",
    "            \"industry\": industry,\n",
    "            \"salary_range\": salary_range,\n",
    "            \"telecommuting\": int(telecommuting),\n",
    "            \"has_company_logo\": int(has_company_logo),\n",
    "            \"has_questions\": int(has_questions)\n",
    "        }\n",
    "\n",
    "        with st.spinner(\"Scanning job...\"):\n",
    "            result = scan_job(job_data)\n",
    "            st.success(\"Job scanned successfully!\")\n",
    "            st.write(f\"*Prediction*: {result['prediction_label']}\")\n",
    "            st.write(f\"*Fraud Probability*: {result['fraud_probability']:.2f}\")\n",
    "\n",
    "# Page 3: Retrain Model\n",
    "elif page == \"Retrain Model\":\n",
    "    st.subheader(\"Retrain the Model\")\n",
    "    st.write(\"Upload a labeled CSV file to retrain the model. The CSV must include a 'fraudulent' column with labels (0 or 1).\")\n",
    "\n",
    "    retrain_file = st.file_uploader(\"Choose a labeled CSV file\", type=\"csv\", key=\"retrain_file\")\n",
    "\n",
    "    if retrain_file is not None:\n",
    "        new_data = pd.read_csv(retrain_file)\n",
    "        required_columns = ['title', 'description', 'fraudulent']\n",
    "        missing_columns = [col for col in required_columns if col not in new_data.columns]\n",
    "        if missing_columns:\n",
    "            st.error(f\"Missing required columns: {missing_columns}. Please ensure the CSV contains 'title', 'description', and 'fraudulent'.\")\n",
    "            st.stop()\n",
    "\n",
    "        st.success(\"Labeled data uploaded successfully!\")\n",
    "        st.markdown(\"### Data Preview\")\n",
    "        st.dataframe(new_data.head())\n",
    "\n",
    "        if st.button(\"Retrain Model\"):\n",
    "            with st.spinner(\"Retraining the model...\"):\n",
    "                # Preprocessing\n",
    "                new_data = new_data.drop_duplicates()\n",
    "                if 'job_id' in new_data.columns:\n",
    "                    new_data = new_data.drop(columns=['job_id'])\n",
    "\n",
    "                text_columns = ['title', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "                categorical_columns = ['location', 'department', 'employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
    "                for col in text_columns:\n",
    "                    if col in new_data.columns:\n",
    "                        new_data[col] = new_data[col].fillna(\"Not Provided\")\n",
    "                    else:\n",
    "                        new_data[col] = \"Not Provided\"\n",
    "                for col in categorical_columns:\n",
    "                    if col in new_data.columns:\n",
    "                        new_data[col] = new_data[col].fillna(\"Unknown\")\n",
    "                    else:\n",
    "                        new_data[col] = \"Unknown\"\n",
    "\n",
    "                binary_columns = ['telecommuting', 'has_company_logo', 'has_questions']\n",
    "                for col in binary_columns:\n",
    "                    if col in new_data.columns:\n",
    "                        new_data[col] = new_data[col].fillna(0)\n",
    "                    else:\n",
    "                        new_data[col] = 0\n",
    "\n",
    "                new_data['description_clean'] = new_data['description'].apply(advanced_preprocess_text)\n",
    "                new_data['company_profile_clean'] = new_data['company_profile'].apply(advanced_preprocess_text)\n",
    "                new_data['title_clean'] = new_data['title'].apply(advanced_preprocess_text)\n",
    "\n",
    "                # Retrain TF-IDF vectorizers\n",
    "                tfidf_desc = TfidfVectorizer(max_features=5000)\n",
    "                tfidf_comp = TfidfVectorizer(max_features=5000)\n",
    "                tfidf_title = TfidfVectorizer(max_features=5000)\n",
    "                X_desc = tfidf_desc.fit_transform(new_data['description_clean'])\n",
    "                X_comp = tfidf_comp.fit_transform(new_data['company_profile_clean'])\n",
    "                X_title = tfidf_title.fit_transform(new_data['title_clean'])\n",
    "\n",
    "                if 'salary_range' in new_data.columns:\n",
    "                    new_data['has_salary_range'] = new_data['salary_range'].notnull().astype(int)\n",
    "                    new_data['salary_avg'] = new_data['salary_range'].apply(parse_salary)\n",
    "                else:\n",
    "                    new_data['has_salary_range'] = 0\n",
    "                    new_data['salary_avg'] = 0\n",
    "\n",
    "                # Recalculate fraud rates for target encoding\n",
    "                fraud_rate = {}\n",
    "                cat_features = ['employment_type', 'required_experience', 'industry']\n",
    "                for col in cat_features:\n",
    "                    fraud_rate[col] = new_data.groupby(col)['fraudulent'].mean().to_dict()\n",
    "                for col in cat_features:\n",
    "                    new_data[f'{col}_target_enc'] = new_data[col].map(fraud_rate[col]).fillna(new_data['fraudulent'].mean())\n",
    "\n",
    "                new_data['desc_length'] = new_data['description'].apply(len)\n",
    "                new_data['urgent_flag'] = new_data['description'].str.contains('urgent|immediate|asap|now|pressing|hurry|limited time', case=False, na=False).astype(int)\n",
    "\n",
    "                binary_features = ['telecommuting', 'has_company_logo', 'has_questions', 'has_salary_range']\n",
    "                X_binary = new_data[binary_features].values\n",
    "                X_extra = new_data[['salary_avg', 'desc_length', 'urgent_flag', 'employment_type_target_enc', 'required_experience_target_enc', 'industry_target_enc']].values\n",
    "                X = np.hstack((X_desc.toarray(), X_comp.toarray(), X_title.toarray(), X_binary, X_extra))\n",
    "                y = new_data['fraudulent'].values\n",
    "\n",
    "                # Retrain the XGBoost model\n",
    "                xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "                xgb_model.fit(X, y)\n",
    "\n",
    "                # Save the updated models and vectorizers\n",
    "                joblib.dump(xgb_model, 'job_fraud_xgb_revised_threshold_0_2.pkl')\n",
    "                joblib.dump(tfidf_desc, 'tfidf_desc_revised.pkl')\n",
    "                joblib.dump(tfidf_comp, 'tfidf_comp_revised.pkl')\n",
    "                joblib.dump(tfidf_title, 'tfidf_title_revised.pkl')\n",
    "                joblib.dump(fraud_rate, 'fraud_rate.pkl')\n",
    "\n",
    "                st.success(\"Model retrained and saved successfully! Please restart the app to use the updated model.\")\n",
    "\n",
    "# Page 4: Explain Predictions with SHAP\n",
    "elif page == \"Explain Predictions\":\n",
    "    st.subheader(\"Explain Predictions with SHAP\")\n",
    "    st.write(\"Select a job to see why it was classified as fraudulent or genuine.\")\n",
    "\n",
    "    # Check session state for df and X\n",
    "    if st.session_state.df is None or st.session_state.X is None:\n",
    "        st.error(\"Please run a CSV prediction first on the 'CSV Prediction' page.\")\n",
    "    else:\n",
    "        df = st.session_state.df\n",
    "        X = st.session_state.X\n",
    "        job_titles = df['title'].tolist()\n",
    "        selected_job = st.selectbox(\"Select a job to explain:\", job_titles)\n",
    "        selected_idx = df[df['title'] == selected_job].index[0]\n",
    "\n",
    "        shap_values = explainer.shap_values(X[selected_idx:selected_idx+1])\n",
    "        shap_expected_value = explainer.expected_value\n",
    "\n",
    "        st.markdown(\"### SHAP Force Plot\")\n",
    "        plt.figure()\n",
    "        shap.force_plot(shap_expected_value, shap_values, X[selected_idx:selected_idx+1], matplotlib=True, show=False)\n",
    "        st.pyplot(plt)\n",
    "\n",
    "        # Define binary_features\n",
    "        binary_features = ['telecommuting', 'has_company_logo', 'has_questions', 'has_salary_range']\n",
    "        \n",
    "        feature_names = (tfidf_desc.get_feature_names_out().tolist() +\n",
    "                         tfidf_comp.get_feature_names_out().tolist() +\n",
    "                         tfidf_title.get_feature_names_out().tolist() +\n",
    "                         binary_features +\n",
    "                         ['salary_avg', 'desc_length', 'urgent_flag', 'employment_type_target_enc',\n",
    "                          'required_experience_target_enc', 'industry_target_enc'])\n",
    "        st.write(\"Note: Features are in order: description, company profile, title, binary features, and extra features.\")\n",
    "\n",
    "# Page 5: Email Alerts for High-Risk Jobs\n",
    "elif page == \"Email Alerts\":\n",
    "    st.subheader(\"Email Alerts for High-Risk Jobs\")\n",
    "    st.write(\"Enter your email credentials to send alerts for jobs with fraud probability > 80%.\")\n",
    "\n",
    "    # Check session state for df\n",
    "    if st.session_state.df is None:\n",
    "        st.error(\"Please run a CSV prediction first on the 'CSV Prediction' page.\")\n",
    "    else:\n",
    "        df = st.session_state.df\n",
    "        recipient_email = st.text_input(\"Recipient Email Address:\")\n",
    "        sender_email = st.text_input(\"Sender Email Address (e.g., your Gmail):\")\n",
    "        sender_password = st.text_input(\"Sender Email Password (e.g., Gmail App Password):\", type=\"password\")\n",
    "\n",
    "        if st.button(\"Send Email Alert\"):\n",
    "            if not recipient_email or not sender_email or not sender_password:\n",
    "                st.error(\"Please fill in all email fields.\")\n",
    "            else:\n",
    "                high_risk_jobs = df[df['Fraud_Probability'] > 0.8][['title', 'description', 'Fraud_Probability']]\n",
    "\n",
    "                if len(high_risk_jobs) == 0:\n",
    "                    st.warning(\"No high-risk jobs (fraud probability > 80%) found.\")\n",
    "                else:\n",
    "                    subject = \"High-Risk Job Listings Alert\"\n",
    "                    body = \"The following jobs have a fraud probability greater than 80%:\\n\\n\"\n",
    "                    for idx, row in high_risk_jobs.iterrows():\n",
    "                        body += f\"Title: {row['title']}\\nDescription: {row['description']}\\nFraud Probability: {row['Fraud_Probability']:.2f}\\n\\n\"\n",
    "\n",
    "                    msg = MIMEMultipart()\n",
    "                    msg['From'] = sender_email\n",
    "                    msg['To'] = recipient_email\n",
    "                    msg['Subject'] = subject\n",
    "                    msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "                    try:\n",
    "                        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "                        server.starttls()\n",
    "                        server.login(sender_email, sender_password)\n",
    "                        server.sendmail(sender_email, recipient_email, msg.as_string())\n",
    "                        server.quit()\n",
    "                        st.success(f\"Email alert sent to {recipient_email} with {len(high_risk_jobs)} high-risk jobs!\")\n",
    "                    except Exception as e:\n",
    "                        st.error(f\"Failed to send email: {e}. Ensure your credentials are correct and you’re using an app-specific password for Gmail.\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"*App developed by Interpretive Edge*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f6da9-efb5-4c33-8c29-51981c2a2a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
